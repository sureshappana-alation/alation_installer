# This is a basic workflow to help you get started with Actions

name: unified-build

# Controls when the action will run. 
on:
#   # Triggers the workflow on push or pull request events but only for the main branch
  push:
    branches: [ main ]
#   pull_request:
#     branches: [ main ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:
    inputs:
      ALATION_ANALYTICS:
        description: 'Alation Analytics version'
        required: false
      OCF:
        description: 'OCF version'
        required: false


jobs:
  build:
    runs-on: ubuntu-latest
    env:
      S3_DEV_BUCKET_URL: "s3://${{ secrets.S3_DEV_BUCKET_NAME }}"
      S3_RELEASE_BUCKET_URL: "s3://${{ secrets.S3_RELEASE_BUCKET_NAME }}"
    steps:
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v1

      - name: Checkout code
        uses: actions/checkout@v2
      
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_S3_REGION }}

      - name: Run environment versions files
        run: |
          for f in ${{ github.workspace }}/versions/*.sh; do
            cat "$f"
            echo
          done >> $GITHUB_ENV
      - name: Set environment variables
        run: |
          echo KURL_FILE_NAME=kurl-${{ env.KURL }}.tar.gz >> $GITHUB_ENV

      - name: Check if Kurl Package exists in S3
        run: |
          exists=$(aws s3api list-objects-v2 --bucket ${{ secrets.S3_DEV_BUCKET_NAME }} --query "contains(Contents[].Key, '{{ env.KURL_FILE_NAME }}')")
          if [ not $exists ]; then
            echo "Kurl Package ${{ env.KURL_FILE_NAME }} does not exists in S3. Downloading it"
            curl -LO https://k8s.kurl.sh/bundle/${{ env.KURL_FILE_NAME }}
            echo "Uploading Kurl Package with version ${{ env.KURL_FILE_NAME }} to S3"
            aws s3 cp ${{env.KURL_FILE_NAME}} ${{ env.S3_DEV_BUCKET_URL }}/${{env.KURL_FILE_NAME}}
          else
            echo "Kurl Package ${{env.KURL_FILE_NAME}} exists in S3. Skipping downloading"
          fi

      # - name: Run environment versions files
      #   id: data
      #   run: |
      #     echo ::set-output name=data::$(for f in ${{ github.workspace }}/versions/*.sh; do
      #       cat "$f"
      #       echo
      #     done)
      # - name: Print output
      #   run: echo ${{ steps.data.outputs.data}}
      # - name: Set services list
      #   id: service-list
      #   run: export SERVICES=(alation_analytics ocf) >> $GITHUB_ENV

      # - name: Read version files
      #   run: |
      #     for f in ./versions/*.sh; do
      #       cat "$f"
      #       echo
      #     done >> $GITHUB_ENV
      # - name: Testing
      #   id: services
      #   run: |
      #     services=()
      #     for i in ./versions/*.sh; do
      #       while read line || [ -n "$line" ];
      #       do
      #           services+=($(echo $line | awk '{split($0,a,"="); printf a[1]}'))
      #       done < "${i}"
      #       cat "$i"
      #       echo
      #     done  >> $GITHUB_ENV
      #     echo "${services[@]}"
      #     echo ::set-output name=arr::${services[@]}
      
      # - name: Print environment variables
      #   run: echo $OCF
      
      # - name: Print environment variables
      #   run: echo ${{ env.OCF }} ${{ env.ALATION_ANALYTICS }}
      
      # - name: Print outputs
      #   run: |
      #     mkdir -p archive
      #     for i in ${{ steps.services.outputs.arr }}; do
      #       echo ${{ format('{0}.{1}', env $i) }}
      #     done
      # - name: Services vars1
      #   run: echo ${{ env[$SERVICES[0]] }}
      - name: Set env variables
        run: |
          echo BASE_DIR=./alation >> $GITHUB_ENV
          echo RESOURCE_DIR=./alation/res >> $GITHUB_ENV
          echo MODULES_DIR=./alation/res/modules >> $GITHUB_ENV
          echo KURL_PATCH_DIR=./alation/res/kurl_patch >> $GITHUB_ENV
          echo ALATION_OUTPUT=alation-$GITHUB_RUN_NUMBER.tar.gz >> $GITHUB_ENV
      - name: Creating required directories
        run: |
          mkdir -p ${{ env.BASE_DIR }}
          mkdir -p ${{ MODULES_DIR }}
          mkdir -p ${{ KURL_PATCH_DIR }}
      - name: Copy content from source code to archiving directory
        run: |
          cp -r ${{ github.workspace }}/res $BASE_DIR/

      - name: Download files from S3
        run: |
          aws s3 cp ${{ env.S3_DEV_BUCKET_URL }}/alation_analytics-${{ env.ALATION_ANALYTICS }}.tar.gz ${{env.SERVICES_DIR}}/alation_analytics
          aws s3 cp ${{ env.S3_DEV_BUCKET_URL }}/ocf-${{ env.OCF }}.tar.gz ${{env.SERVICES_DIR}}/ocf
          aws s3 cp ${{ env.S3_DEV_BUCKET_URL }}/kurl-${{ env.KURL }}.tar.gz ${{env.RESOURCE_DIR}}
          ls -al ${{env.INSTALLER_DIR}}

      - name: Build and store docker tarball
        id: docker_build
        uses: docker/build-push-action@v2
        with:
          context: ./installer
          push: false
          tags: alation/installer:latest
          outputs: type=docker,dest=.
      
      - name: List of files
        run: find ${{ env.BASE_DIR }}
      
      - name: Extract installer binary from docker tarball
        run: |
          tar xvzf out/installer.tar.gz
          cp out/installer/installer ${{ env.BASE_DIR }}
     
      # - name: List of files
      #   run: find ./archive      
     
      # - name: Compress files
      #   run: tar -cvzf ${{ env.ALATION_OUTPUT }} ./archive
      
      # - name: Upload the final artifact to S3
      #   run: aws s3 cp ${{ env.ALATION_OUTPUT }} ${{ env.S3_RELEASE_BUCKET_URL }}/${{ env.ALATION_OUTPUT }}

      # - name: Image digest
      #   run: echo ${{ steps.docker_build.outputs.digest }}

      # - name: List of files
      #   run: ls -al ./archive

      # - name: Compress files
      #   run: tar -cvzf alation-0.3.0.tar.gz ./archive

#       - name: Create zip
#         uses: ihiroky/archive-action@v1
#         with:
#           root_dir: path_to_arhive_root_directory
#           file_path: path_to_archive.zip
